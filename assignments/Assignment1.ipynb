{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Assignment 1 - Loss functions and gradient descent\n",
    "\n",
    "Paul E. Anderson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'..') # Change this based on your system\n",
    "\n",
    "import py487"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "In this assignment and when calculating the log, I add a small value 1e-10 to make sure that we are always > 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "np.random.seed(4)\n",
    "X, t = datasets.make_blobs(n_samples=100, centers=3, n_features=2, center_box=(0, 10))\n",
    "plt.plot(X[:, 0][t == 0], X[:, 1][t == 0], marker='^',linestyle=\"None\" ,color='yellow')\n",
    "plt.plot(X[:, 0][t == 1], X[:, 1][t == 1], marker='s',linestyle=\"None\",color='orange')\n",
    "plt.plot(X[:, 0][t == 2], X[:, 1][t == 2], marker='o',linestyle=\"None\",color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For give the colors and how they show on the screen, I'm choosing them to represent a ficticious orange, lemons, and limes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Orange\n",
       "1      Lemon\n",
       "2     Orange\n",
       "3     Orange\n",
       "4      Lemon\n",
       "       ...  \n",
       "95      Lime\n",
       "96     Lemon\n",
       "97      Lime\n",
       "98      Lime\n",
       "99     Lemon\n",
       "Length: 100, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "t_fruit = pd.Series(t).map({0:\"Lemon\",1:\"Orange\",2:\"Lime\"})\n",
    "t_fruit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a simple classifier to examine our loss functions. We'll stick with k-nearest neighbor classifier for this example. We will use the sklearn implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "clf.fit(X, t_fruit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Lemon       0.87      0.97      0.92        34\n",
      "        Lime       1.00      0.97      0.98        33\n",
      "      Orange       0.97      0.88      0.92        33\n",
      "\n",
      "    accuracy                           0.94       100\n",
      "   macro avg       0.95      0.94      0.94       100\n",
      "weighted avg       0.94      0.94      0.94       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_fruit_pred = clf.predict(X)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(t_fruit, y_fruit_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemon</th>\n",
       "      <th>Lime</th>\n",
       "      <th>Orange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Lemon      Lime    Orange\n",
       "0   0.333333  0.000000  0.666667\n",
       "1   1.000000  0.000000  0.000000\n",
       "2   0.333333  0.000000  0.666667\n",
       "3   0.000000  0.000000  1.000000\n",
       "4   0.666667  0.000000  0.333333\n",
       "..       ...       ...       ...\n",
       "95  0.000000  1.000000  0.000000\n",
       "96  0.666667  0.000000  0.333333\n",
       "97  0.000000  1.000000  0.000000\n",
       "98  0.000000  1.000000  0.000000\n",
       "99  0.666667  0.333333  0.000000\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_fruit_probs_pred = pd.DataFrame(clf.predict_proba(X),columns=clf.classes_)\n",
    "y_fruit_probs_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we are going to start incorporating pytorch, I am going to start showing you their built-in functions. Below is the KL-divergence. Before we can call that function, we need to define the target. Here ya go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemon</th>\n",
       "      <th>Lime</th>\n",
       "      <th>Orange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Lemon  Lime  Orange\n",
       "0     0.0   0.0     1.0\n",
       "1     1.0   0.0     0.0\n",
       "2     0.0   0.0     1.0\n",
       "3     0.0   0.0     1.0\n",
       "4     1.0   0.0     0.0\n",
       "..    ...   ...     ...\n",
       "95    0.0   1.0     0.0\n",
       "96    1.0   0.0     0.0\n",
       "97    0.0   1.0     0.0\n",
       "98    0.0   1.0     0.0\n",
       "99    1.0   0.0     0.0\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_fruit_probs = pd.get_dummies(t_fruit).astype(float)\n",
    "y_fruit_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkl_div\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msize_average\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreduce\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreduction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlog_target\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "The `Kullback-Leibler divergence Loss\n",
       "<https://en.wikipedia.org/wiki/Kullback-Leibler_divergence>`__\n",
       "\n",
       "See :class:`~torch.nn.KLDivLoss` for details.\n",
       "\n",
       "Args:\n",
       "    input: Tensor of arbitrary shape in log-probabilities.\n",
       "    target: Tensor of the same shape as input. See :attr:`log_target` for\n",
       "        the target's interpretation.\n",
       "    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
       "        the losses are averaged over each loss element in the batch. Note that for\n",
       "        some losses, there multiple elements per sample. If the field :attr:`size_average`\n",
       "        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
       "        when reduce is ``False``. Default: ``True``\n",
       "    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
       "        losses are averaged or summed over observations for each minibatch depending\n",
       "        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
       "        batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
       "    reduction (str, optional): Specifies the reduction to apply to the output:\n",
       "        ``'none'`` | ``'batchmean'`` | ``'sum'`` | ``'mean'``.\n",
       "        ``'none'``: no reduction will be applied\n",
       "        ``'batchmean'``: the sum of the output will be divided by the batchsize\n",
       "        ``'sum'``: the output will be summed\n",
       "        ``'mean'``: the output will be divided by the number of elements in the output\n",
       "        Default: ``'mean'``\n",
       "    log_target (bool): A flag indicating whether ``target`` is passed in the log space.\n",
       "        It is recommended to pass certain distributions (like ``softmax``)\n",
       "        in the log space to avoid numerical issues caused by explicit ``log``.\n",
       "        Default: ``False``\n",
       "\n",
       ".. note::\n",
       "    :attr:`size_average` and :attr:`reduce` are in the process of being deprecated,\n",
       "    and in the meantime, specifying either of those two args will override :attr:`reduction`.\n",
       "\n",
       ".. note::\n",
       "    :attr:`reduction` = ``'mean'`` doesn't return the true kl divergence value, please use\n",
       "    :attr:`reduction` = ``'batchmean'`` which aligns with KL math definition.\n",
       "    In the next major release, ``'mean'`` will be changed to be the same as 'batchmean'.\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/tljh/user/lib/python3.9/site-packages/torch/nn/functional.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "?torch.nn.functional.kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15106440990030112"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "float(torch.nn.functional.kl_div(torch.tensor(np.log(y_fruit_probs_pred.values+1e-10)), torch.tensor(y_fruit_probs.values),reduction='batchmean').numpy())\n"
   ]
  },
  {
   "attachments": {
    "0e98e0a8-b9ca-4a2f-bb83-9834365c9bbe.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's implement our own KL-divergence\n",
    "\n",
    "![image.png](attachment:0e98e0a8-b9ca-4a2f-bb83-9834365c9bbe.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notation, $P$ is target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemon</th>\n",
       "      <th>Lime</th>\n",
       "      <th>Orange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Lemon      Lime    Orange\n",
       "0   0.333333  0.000000  0.666667\n",
       "1   1.000000  0.000000  0.000000\n",
       "2   0.333333  0.000000  0.666667\n",
       "3   0.000000  0.000000  1.000000\n",
       "4   0.666667  0.000000  0.333333\n",
       "..       ...       ...       ...\n",
       "95  0.000000  1.000000  0.000000\n",
       "96  0.666667  0.000000  0.333333\n",
       "97  0.000000  1.000000  0.000000\n",
       "98  0.000000  1.000000  0.000000\n",
       "99  0.666667  0.333333  0.000000\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_fruit_probs_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemon</th>\n",
       "      <th>Lime</th>\n",
       "      <th>Orange</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Lemon  Lime  Orange\n",
       "0     0.0   0.0     1.0\n",
       "1     1.0   0.0     0.0\n",
       "2     0.0   0.0     1.0\n",
       "3     0.0   0.0     1.0\n",
       "4     1.0   0.0     0.0\n",
       "..    ...   ...     ...\n",
       "95    0.0   1.0     0.0\n",
       "96    1.0   0.0     0.0\n",
       "97    0.0   1.0     0.0\n",
       "98    0.0   1.0     0.0\n",
       "99    1.0   0.0     0.0\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_fruit_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1510644100003011"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py487.functional.kl_div(np.log(y_fruit_probs_pred.values+1e-10),y_fruit_probs.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/39d0c6b14cd7381cd3145718f693c114b84e7960\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again $P$ is target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mweight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0msize_average\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mignore_index\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreduce\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreduction\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "This criterion computes the cross entropy loss between input logits and target.\n",
       "\n",
       "See :class:`~torch.nn.CrossEntropyLoss` for details.\n",
       "\n",
       "Args:\n",
       "    input (Tensor) : Predicted unnormalized logits;\n",
       "        see Shape section below for supported shapes.\n",
       "    target (Tensor) : Ground truth class indices or class probabilities;\n",
       "        see Shape section below for supported shapes.\n",
       "    weight (Tensor, optional): a manual rescaling weight given to each\n",
       "        class. If given, has to be a Tensor of size `C`\n",
       "    size_average (bool, optional): Deprecated (see :attr:`reduction`). By default,\n",
       "        the losses are averaged over each loss element in the batch. Note that for\n",
       "        some losses, there multiple elements per sample. If the field :attr:`size_average`\n",
       "        is set to ``False``, the losses are instead summed for each minibatch. Ignored\n",
       "        when reduce is ``False``. Default: ``True``\n",
       "    ignore_index (int, optional): Specifies a target value that is ignored\n",
       "        and does not contribute to the input gradient. When :attr:`size_average` is\n",
       "        ``True``, the loss is averaged over non-ignored targets. Note that\n",
       "        :attr:`ignore_index` is only applicable when the target contains class indices.\n",
       "        Default: -100\n",
       "    reduce (bool, optional): Deprecated (see :attr:`reduction`). By default, the\n",
       "        losses are averaged or summed over observations for each minibatch depending\n",
       "        on :attr:`size_average`. When :attr:`reduce` is ``False``, returns a loss per\n",
       "        batch element instead and ignores :attr:`size_average`. Default: ``True``\n",
       "    reduction (str, optional): Specifies the reduction to apply to the output:\n",
       "        ``'none'`` | ``'mean'`` | ``'sum'``. ``'none'``: no reduction will be applied,\n",
       "        ``'mean'``: the sum of the output will be divided by the number of\n",
       "        elements in the output, ``'sum'``: the output will be summed. Note: :attr:`size_average`\n",
       "        and :attr:`reduce` are in the process of being deprecated, and in the meantime,\n",
       "        specifying either of those two args will override :attr:`reduction`. Default: ``'mean'``\n",
       "    label_smoothing (float, optional): A float in [0.0, 1.0]. Specifies the amount\n",
       "        of smoothing when computing the loss, where 0.0 means no smoothing. The targets\n",
       "        become a mixture of the original ground truth and a uniform distribution as described in\n",
       "        `Rethinking the Inception Architecture for Computer Vision <https://arxiv.org/abs/1512.00567>`__. Default: :math:`0.0`.\n",
       "\n",
       "Shape:\n",
       "    - Input: Shape :math:`(C)`, :math:`(N, C)` or :math:`(N, C, d_1, d_2, ..., d_K)` with :math:`K \\geq 1`\n",
       "      in the case of `K`-dimensional loss.\n",
       "    - Target: If containing class indices, shape :math:`()`, :math:`(N)` or :math:`(N, d_1, d_2, ..., d_K)` with\n",
       "      :math:`K \\geq 1` in the case of K-dimensional loss where each value should be between :math:`[0, C)`.\n",
       "      If containing class probabilities, same shape as the input and each value should be between :math:`[0, 1]`.\n",
       "\n",
       "    where:\n",
       "\n",
       "    .. math::\n",
       "        \\begin{aligned}\n",
       "            C ={} & \\text{number of classes} \\\\\n",
       "            N ={} & \\text{batch size} \\\\\n",
       "        \\end{aligned}\n",
       "\n",
       "Examples::\n",
       "\n",
       "    >>> # Example of target with class indices\n",
       "    >>> input = torch.randn(3, 5, requires_grad=True)\n",
       "    >>> target = torch.randint(5, (3,), dtype=torch.int64)\n",
       "    >>> loss = F.cross_entropy(input, target)\n",
       "    >>> loss.backward()\n",
       "    >>>\n",
       "    >>> # Example of target with class probabilities\n",
       "    >>> input = torch.randn(3, 5, requires_grad=True)\n",
       "    >>> target = torch.randn(3, 5).softmax(dim=1)\n",
       "    >>> loss = F.cross_entropy(input, target)\n",
       "    >>> loss.backward()\n",
       "\u001b[0;31mFile:\u001b[0m      /opt/tljh/user/lib/python3.9/site-packages/torch/nn/functional.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?torch.nn.functional.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15106441020030112"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(torch.nn.functional.cross_entropy(\n",
    "    torch.tensor(np.log(y_fruit_probs_pred.values+1e-10)), \n",
    "    torch.tensor(y_fruit_probs.values)).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1510644099003011"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py487.functional.cross_entropy(np.log(y_fruit_probs_pred.values+1e-10),y_fruit_probs.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first take on gradient descent will assume you can symbolically find the gradient of a function. We will use:\n",
    "\n",
    "We want to minimize:\n",
    "\n",
    "$J_1(\\theta) = \\theta^2$\n",
    "\n",
    "$J_2(\\theta) = (1-\\theta)^2$\n",
    "\n",
    "Gradient descent says:\n",
    "\n",
    "$\\theta = \\theta - \\alpha \\frac{1}{2} \\left(\\frac{dJ_1}{d\\theta}+\\frac{dJ_2}{d\\theta}\\right)$\n",
    "\n",
    "We will set $\\alpha=0.1$.\n",
    "\n",
    "We will now define the derivatives programmatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_func1 = lambda theta: 2*theta\n",
    "gradient_func1(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_func2 = lambda theta: -2*(1-theta)\n",
    "gradient_func2(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      5.0000\n",
       "1      4.1000\n",
       "2      3.3800\n",
       "3      2.8040\n",
       "4      2.3432\n",
       "        ...  \n",
       "99     0.5000\n",
       "100    0.5000\n",
       "101    0.5000\n",
       "102    0.5000\n",
       "103    0.5000\n",
       "Length: 104, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetas = py487.functional.minimize_gradient_descent([gradient_func1,gradient_func2],0.1,5)\n",
    "pd.Series(thetas)\n",
    "# please note that I only add the pd.Series, so the output is nicely formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theta</th>\n",
       "      <th>J1</th>\n",
       "      <th>J2</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>20.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.1000</td>\n",
       "      <td>16.810000</td>\n",
       "      <td>9.610000</td>\n",
       "      <td>13.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.3800</td>\n",
       "      <td>11.424400</td>\n",
       "      <td>5.664400</td>\n",
       "      <td>8.544400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.8040</td>\n",
       "      <td>7.862416</td>\n",
       "      <td>3.254416</td>\n",
       "      <td>5.558416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.3432</td>\n",
       "      <td>5.490586</td>\n",
       "      <td>1.804186</td>\n",
       "      <td>3.647386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      theta         J1         J2          R\n",
       "0    5.0000  25.000000  16.000000  20.500000\n",
       "1    4.1000  16.810000   9.610000  13.210000\n",
       "2    3.3800  11.424400   5.664400   8.544400\n",
       "3    2.8040   7.862416   3.254416   5.558416\n",
       "4    2.3432   5.490586   1.804186   3.647386\n",
       "..      ...        ...        ...        ...\n",
       "99   0.5000   0.250000   0.250000   0.250000\n",
       "100  0.5000   0.250000   0.250000   0.250000\n",
       "101  0.5000   0.250000   0.250000   0.250000\n",
       "102  0.5000   0.250000   0.250000   0.250000\n",
       "103  0.5000   0.250000   0.250000   0.250000\n",
       "\n",
       "[104 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J1s = [theta**2 for theta in thetas]\n",
    "J2s = [(1-theta)**2 for theta in thetas]\n",
    "results = pd.DataFrame({\"theta\":thetas, \"J1\":J1s,\"J2\":J2s})\n",
    "results[\"R\"] = (results[\"J1\"]+results[\"J2\"])/2\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what if you can't or don't want to find the derivatives symbolically? \n",
    "You can always estimate the gradient analytically using the difference quotient:\n",
    "\n",
    "$[J(\\theta+h)-J(\\theta)]/h$,\n",
    "\n",
    "where h is a scalar parameter. Let's give it a shot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J1_func = lambda theta: theta**2\n",
    "J1_func(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J2_func = lambda theta: (1-theta)**2\n",
    "J2_func(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.5"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_func = lambda theta: 1/2*(J1_func(theta)+J2_func(theta))\n",
    "R_func(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration,gradient,theta,previous theta\n",
      "0,9.009999999999962,4.099000000000004,5\n",
      "10,0.967441383424017,0.8819765533696056,0.9787206917120073\n",
      "20,0.10387822756507958,0.5365512910260312,0.5469391137825391\n",
      "30,0.011153839753963446,0.49946153590158415,0.5005769198769805\n",
      "40,0.001197634424204841,0.4954790537696807,0.4955988172121012\n",
      "50,0.00012859501711259824,0.4950514380068455,0.49506429750855674\n",
      "60,1.380778482107381e-05,0.4950055231139294,0.49500690389241153\n",
      "70,1.4825996041967215e-06,0.4950005930398427,0.4950007412998031\n",
      "80,1.5919291995736273e-07,0.4950000636771684,0.4950000795964604\n",
      "90,1.7093210180618712e-08,0.4950000068372845,0.49500000854660553\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      5.000000\n",
       "1      4.099000\n",
       "2      3.378200\n",
       "3      2.801560\n",
       "4      2.340248\n",
       "         ...   \n",
       "96     0.495000\n",
       "97     0.495000\n",
       "98     0.495000\n",
       "99     0.495000\n",
       "100    0.495000\n",
       "Length: 101, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetas = py487.functional.minimize_gradient_descent_analytically(R_func,0.1,5,0.01)\n",
    "pd.Series(thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25002499999082317"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_func(thetas[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_func(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
