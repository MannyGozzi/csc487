{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to FCNN\n",
    "\n",
    "## Learning Objectives\n",
    "* Constructing, training, and evaluating a FCNN.\n",
    "\n",
    "## Submission Instructions\n",
    "**After completing the assignments, please upload a PDF output of this notebook.**\n",
    "\n",
    "This is an individual assignment, but you may discuss your code with your neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'..') # change this for your system\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import py487"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "np.random.seed(4)\n",
    "X, t = datasets.make_blobs(n_samples=100, centers=3, n_features=2, center_box=(0, 10))\n",
    "plt.plot(X[:, 0][t == 0], X[:, 1][t == 0], marker='^',linestyle=\"None\" ,color='yellow')\n",
    "plt.plot(X[:, 0][t == 1], X[:, 1][t == 1], marker='s',linestyle=\"None\",color='orange')\n",
    "plt.plot(X[:, 0][t == 2], X[:, 1][t == 2], marker='o',linestyle=\"None\",color='green')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment instructions\n",
    "Construct and evaluate a multi-layer perceptron similar to the XOR example we've reviewed as a class. Evaluation must be carried out on a test set that was not used for training. You must stick to one hidden layer and then the output layer. The number of nodes in the hidden layer is entirely up to you. The decisions on how to code your solution is up to you, but you must use pytorch and structure your solution similar to how we coded the XOR. You can bring the training loop outside the class definition as that was just my preference for the XOR example. You must compute precision, recall, and the f1-score for the testing dataset and provide a breakdown for each class. Be careful about overfitting and show how you checked for overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,nhidden=3,nin=2):\n",
    "        super(Net, self).__init__()\n",
    "        self.nhidden = nhidden\n",
    "        self.nin = nin\n",
    "        hidden_nodes = []\n",
    "        for _ in range(nhidden):\n",
    "            hidden_nodes.append(torch.nn.Parameter((torch.rand(self.nin+1,1)-.5)*2/torch.sqrt(torch.tensor(2))))\n",
    "        self.hidden_nodes = nn.ParameterList(hidden_nodes)\n",
    "        self.output = nn.Linear(nhidden, 3, bias=True)\n",
    "        self.loss = None\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.unfreeze()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.cat((x,-torch.ones((x.shape[0],1))),axis=1)\n",
    "        ys = []\n",
    "        for h in self.hidden_nodes:\n",
    "            ys.append(torch.matmul(x,h))\n",
    "        y = torch.cat(ys,dim=1)\n",
    "        y = torch.sigmoid(y) # end of the hidden layer forward step?\n",
    "        y = torch.sigmoid(self.output(y))\n",
    "        return y\n",
    "\n",
    "    def fit(self, x_data, y_data, nepochs=1000):\n",
    "        optimizer = optim.SGD(self.parameters(), lr=0.5, momentum=0.9)\n",
    "\n",
    "        ntry = 1\n",
    "        while ntry <= 10:\n",
    "            for epoch in range(nepochs):  # loop over the dataset multiple times\n",
    "                #for ix in range(len(x_data)):\n",
    "                inputs, labels = x_data,y_data # x_data[[ix],:],y_data[[ix],:]\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = self(inputs)\n",
    "                #print(inputs,outputs)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # print statistics\n",
    "                if epoch % 100 == 0:\n",
    "                  #print(outputs)\n",
    "                  #print(\"\\n\".join([str(s) for s in list(net.hidden.parameters())]))\n",
    "                  print(f'[{epoch + 1}] loss:',loss.data.numpy())\n",
    "            if torch.sum(self.predict(inputs) == labels)/len(labels) == 1.:\n",
    "                print('Finished training')\n",
    "                break\n",
    "            else:\n",
    "                print('Running the fit loop again,',ntry)\n",
    "            ntry+=1\n",
    "\n",
    "        self.loss = loss.data\n",
    "\n",
    "        return self # Essential an error\n",
    "\n",
    "    def freeze(self):\n",
    "        # Freeze all the parameters in the network\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def unfreeze(self):\n",
    "        # Freeze all the parameters in the network\n",
    "        for param in self.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    def predict(self,x):\n",
    "        return torch.round(self.forward(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 1.0986073\n",
      "[101] loss: 0.8064844\n",
      "[201] loss: 0.7588697\n",
      "[301] loss: 0.73621374\n",
      "[401] loss: 0.7230835\n",
      "[501] loss: 0.71427625\n",
      "[601] loss: 0.70843405\n",
      "[701] loss: 0.70434755\n",
      "[801] loss: 0.70131034\n",
      "[901] loss: 0.6988759\n",
      "Running the fit loop again, 1\n",
      "[1] loss: 0.69665986\n",
      "[101] loss: 0.6944146\n",
      "[201] loss: 0.6903205\n",
      "[301] loss: 0.6774833\n",
      "[401] loss: 0.6706926\n",
      "[501] loss: 0.6687139\n",
      "[601] loss: 0.66577893\n",
      "[701] loss: 0.6625401\n",
      "[801] loss: 0.6586618\n",
      "[901] loss: 0.6545508\n",
      "Running the fit loop again, 2\n",
      "[1] loss: 0.6503327\n",
      "[101] loss: 0.6461388\n",
      "[201] loss: 0.6483133\n",
      "[301] loss: 0.63922316\n",
      "[401] loss: 0.6375531\n",
      "[501] loss: 0.63601786\n",
      "[601] loss: 0.6345605\n",
      "[701] loss: 0.63310987\n",
      "[801] loss: 0.6316051\n",
      "[901] loss: 0.6300421\n",
      "Running the fit loop again, 3\n",
      "[1] loss: 0.6284622\n",
      "[101] loss: 0.62691873\n",
      "[201] loss: 0.62545764\n",
      "[301] loss: 0.62410754\n",
      "[401] loss: 0.6228788\n",
      "[501] loss: 0.62176895\n",
      "[601] loss: 0.6207688\n",
      "[701] loss: 0.6198659\n",
      "[801] loss: 0.61904633\n",
      "[901] loss: 0.61829525\n",
      "Running the fit loop again, 4\n",
      "[1] loss: 0.617597\n",
      "[101] loss: 0.6169376\n",
      "[201] loss: 0.61631185\n",
      "[301] loss: 0.61571944\n",
      "[401] loss: 0.61515975\n",
      "[501] loss: 0.61463076\n",
      "[601] loss: 0.61412996\n",
      "[701] loss: 0.6136545\n",
      "[801] loss: 0.6132018\n",
      "[901] loss: 0.6127694\n",
      "Running the fit loop again, 5\n",
      "[1] loss: 0.6123553\n",
      "[101] loss: 0.61195755\n",
      "[201] loss: 0.6115745\n",
      "[301] loss: 0.6112047\n",
      "[401] loss: 0.6108466\n",
      "[501] loss: 0.610499\n",
      "[601] loss: 0.61016047\n",
      "[701] loss: 0.6098295\n",
      "[801] loss: 0.609504\n",
      "[901] loss: 0.60918134\n",
      "Running the fit loop again, 6\n",
      "[1] loss: 0.6088571\n",
      "[101] loss: 0.6085228\n",
      "[201] loss: 0.60815954\n",
      "[301] loss: 0.6077228\n",
      "[401] loss: 0.6071417\n",
      "[501] loss: 0.6064462\n",
      "[601] loss: 0.60573804\n",
      "[701] loss: 0.60505164\n",
      "[801] loss: 0.60439515\n",
      "[901] loss: 0.6037714\n",
      "Running the fit loop again, 7\n",
      "[1] loss: 0.6031818\n",
      "[101] loss: 0.60262567\n",
      "[201] loss: 0.6021018\n",
      "[301] loss: 0.6016085\n",
      "[401] loss: 0.60114396\n",
      "[501] loss: 0.6007062\n",
      "[601] loss: 0.6002933\n",
      "[701] loss: 0.5999036\n",
      "[801] loss: 0.5995354\n",
      "[901] loss: 0.59918725\n",
      "Running the fit loop again, 8\n",
      "[1] loss: 0.5988577\n",
      "[101] loss: 0.59854525\n",
      "[201] loss: 0.59824884\n",
      "[301] loss: 0.5979674\n",
      "[401] loss: 0.59769976\n",
      "[501] loss: 0.5974449\n",
      "[601] loss: 0.5972021\n",
      "[701] loss: 0.5969705\n",
      "[801] loss: 0.59674925\n",
      "[901] loss: 0.59653765\n",
      "Running the fit loop again, 9\n",
      "[1] loss: 0.59633505\n",
      "[101] loss: 0.59614086\n",
      "[201] loss: 0.5959544\n",
      "[301] loss: 0.5957753\n",
      "[401] loss: 0.5956029\n",
      "[501] loss: 0.5954368\n",
      "[601] loss: 0.5952766\n",
      "[701] loss: 0.5951217\n",
      "[801] loss: 0.5949718\n",
      "[901] loss: 0.59482634\n",
      "Running the fit loop again, 10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [1., 0., 0.]], grad_fn=<RoundBackward0>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()\n",
    "list(net.parameters())\n",
    "x = torch.tensor(X, dtype=torch.float)\n",
    "y = torch.tensor(list(map(lambda num: [1.0 if num == 0 else 0.0, 1.0 if num == 1 else 0.0, 1.0 if num == 2 else 0.0], t)))\n",
    "net.fit(x,y)\n",
    "net.predict(x)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Data Science Workshop - Data Analysis Part 1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
